{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'lm-evaluation-harness'...\n",
      "\n",
      "/teamspace/studios/this_studio/lm-evaluation-harness\n",
      "Obtaining file:///teamspace/studios/this_studio/lm-evaluation-harness\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=0.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (0.28.0)\n",
      "Requirement already satisfied: evaluate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (2.18.0)\n",
      "Requirement already satisfied: jsonlines in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (4.0.0)\n",
      "Requirement already satisfied: numexpr in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (2.9.0)\n",
      "Requirement already satisfied: peft>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (0.10.0)\n",
      "Requirement already satisfied: pybind11>=2.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (2.12.0)\n",
      "Requirement already satisfied: pytablewriter in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (1.2.0)\n",
      "Requirement already satisfied: rouge-score>=0.0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu>=1.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (1.3.2)\n",
      "Requirement already satisfied: sqlitedict in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (2.1.0)\n",
      "Requirement already satisfied: torch>=1.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (2.1.2)\n",
      "Requirement already satisfied: tqdm-multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (0.0.11)\n",
      "Requirement already satisfied: transformers>=4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (4.39.1)\n",
      "Requirement already satisfied: zstandard in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (0.22.0)\n",
      "Requirement already satisfied: dill in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (0.3.8)\n",
      "Requirement already satisfied: word2number in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (1.1)\n",
      "Requirement already satisfied: more-itertools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lm_eval==0.4.2) (10.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (24.0)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (0.4.2)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.2) (3.13.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.2) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.2) (0.6)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.2) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.2) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.2) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.2) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.2) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.2) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.2) (3.9.3)\n",
      "Requirement already satisfied: responses<0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate->lm_eval==0.4.2) (0.18.0)\n",
      "Requirement already satisfied: absl-py in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.2) (2.1.0)\n",
      "Requirement already satisfied: nltk in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.2) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.2) (1.16.0)\n",
      "Requirement already satisfied: portalocker in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (2.8.2)\n",
      "Requirement already satisfied: regex in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (2023.12.25)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (0.9.0)\n",
      "Requirement already satisfied: colorama in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (0.4.6)\n",
      "Requirement already satisfied: lxml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (5.1.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.2) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.2) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.2) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (4.10.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (1.12)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.2) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm_eval==0.4.2) (12.4.99)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.1->lm_eval==0.4.2) (0.15.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonlines->lm_eval==0.4.2) (23.2.0)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.2) (68.2.2)\n",
      "Requirement already satisfied: DataProperty<2,>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.2) (1.0.1)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.2) (1.1.3)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.2) (3.2.0)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.2) (1.3.3)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.2) (0.1.4)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.2) (1.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (4.0.3)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.2) (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.2) (2024.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=1.8->lm_eval==0.4.2) (2.1.5)\n",
      "Requirement already satisfied: click in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge-score>=0.0.4->lm_eval==0.4.2) (8.1.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->lm_eval==0.4.2) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=1.8->lm_eval==0.4.2) (1.3.0)\n",
      "Building wheels for collected packages: lm_eval\n",
      "  Building editable for lm_eval (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lm_eval: filename=lm_eval-0.4.2-0.editable-py3-none-any.whl size=16111 sha256=0bbd8e082249872664d2bb64d383a96b7e3ca21faf8aa298a2b6229ca9ebf7c3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-c50n4b_g/wheels/65/52/b6/325c386c0fc39e293475a5cabcbd32adc46929292e33b194f4\n",
      "Successfully built lm_eval\n",
      "Installing collected packages: lm_eval\n",
      "  Attempting uninstall: lm_eval\n",
      "    Found existing installation: lm_eval 0.4.2\n",
      "    Uninstalling lm_eval-0.4.2:\n",
      "      Successfully uninstalled lm_eval-0.4.2\n",
      "Successfully installed lm_eval-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install lm-evaluation-harness\n",
    "!git clone https://github.com/EleutherAI/lm-evaluation-harness\n",
    "%cd lm-evaluation-harness\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python[server] in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.2.57)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from llama-cpp-python[server]) (4.10.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from llama-cpp-python[server]) (1.24.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from llama-cpp-python[server]) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from llama-cpp-python[server]) (3.1.3)\n",
      "Requirement already satisfied: uvicorn>=0.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from llama-cpp-python[server]) (0.29.0)\n",
      "Requirement already satisfied: fastapi>=0.100.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from llama-cpp-python[server]) (0.110.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from llama-cpp-python[server]) (2.2.1)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from llama-cpp-python[server]) (2.0.0)\n",
      "Requirement already satisfied: starlette-context<0.4,>=0.3.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from llama-cpp-python[server]) (0.3.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi>=0.100.0->llama-cpp-python[server]) (2.6.4)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi>=0.100.0->llama-cpp-python[server]) (0.36.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python[server]) (2.1.5)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic-settings>=2.0.1->llama-cpp-python[server]) (1.0.1)\n",
      "Requirement already satisfied: anyio in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sse-starlette>=1.6.1->llama-cpp-python[server]) (4.3.0)\n",
      "Requirement already satisfied: click>=7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn>=0.22.0->llama-cpp-python[server]) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn>=0.22.0->llama-cpp-python[server]) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100.0->llama-cpp-python[server]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100.0->llama-cpp-python[server]) (2.16.3)\n",
      "Requirement already satisfied: idna>=2.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio->sse-starlette>=1.6.1->llama-cpp-python[server]) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio->sse-starlette>=1.6.1->llama-cpp-python[server]) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio->sse-starlette>=1.6.1->llama-cpp-python[server]) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "# install llama-cpp-python[server]\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install 'llama-cpp-python[server]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment and install python-dotenv if not already installed\n",
    "# %pip install -q python-dotenv\n",
    "\n",
    "# import dotenv to load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure API key is set for WandB and Hub\n",
    "\n",
    "Create .env file in your root and set an API key value like:\n",
    "\n",
    "HUGGINGFACE_TOKEN=\"Enter your token\"\n",
    "\n",
    "WANDB_TOKEN=\"Enter your token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ.get(\"WANDB_TOKEN\") == \"\":\n",
    "    print(f\"please get an API key from WandB at https://wandb.ai/authorize\")\n",
    "    print(f\"and then set your API key value in the .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate and store your credententials in `.netrc` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /teamspace/studios/this_studio/.netrc\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --q wandb\n",
    "WANDB_TOKEN = os.environ.get(\"WANDB_TOKEN\")\n",
    "!wandb login $WANDB_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ.get(\"HUGGINGFACE_TOKEN\") == \"\":\n",
    "    print(f\"please get an API key from HuggingFace at https://huggingface.co/settings/tokens\")\n",
    "    print(f\"and then set your API key value in the .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate and store your credentials in `.git_credentials` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/zeus/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "HUGGINGFACE_TOKEN = os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "!huggingface-cli login --token $HUGGINGFACE_TOKEN --add-to-git-credential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run evaluations on starcoderbase-3b non-quantized model\n",
    "\n",
    "[HuggingFace Model card for starcoderbase-3b](https://huggingface.co/bigcode/starcoderbase-3b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Benchmark] bigbench_code_line_description_generate_until"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcosmo3769\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/teamspace/studios/this_studio/lm-evaluation-harness/wandb/run-20240328_163624-q91q4rp5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfragrant-planet-17\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai/runs/q91q4rp5/workspace\u001b[0m\n",
      "2024-03-28:16:36:28,685 INFO     [__main__.py:251] Verbosity set to INFO\n",
      "2024-03-28:16:36:33,949 INFO     [__main__.py:335] Selected Tasks: ['bigbench_code_line_description_generate_until']\n",
      "2024-03-28:16:36:33,950 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-03-28:16:36:33,951 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'bigcode/starcoderbase-3b', 'trust_remote_code': True}\n",
      "2024-03-28:16:36:33,991 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
      "config.json: 100%|█████████████████████████| 1.05k/1.05k [00:00<00:00, 4.20MB/s]\n",
      "pytorch_model.bin.index.json: 100%|████████| 32.7k/32.7k [00:00<00:00, 66.6MB/s]\n",
      "Downloading shards:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
      "pytorch_model-00001-of-00002.bin:   0%|             | 0.00/10.0G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   0%|     | 21.0M/10.0G [00:00<01:00, 165MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 52.4M/10.0G [00:01<04:04, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 73.4M/10.0G [00:01<02:38, 62.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|    | 83.9M/10.0G [00:01<04:38, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 105M/10.0G [00:02<04:16, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 126M/10.0G [00:02<03:09, 52.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   1%|     | 136M/10.0G [00:02<03:47, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 157M/10.0G [00:03<03:42, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 178M/10.0G [00:03<03:09, 51.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 189M/10.0G [00:04<04:49, 33.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 210M/10.0G [00:04<03:48, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 231M/10.0G [00:04<02:51, 57.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   2%|     | 241M/10.0G [00:05<03:02, 53.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 262M/10.0G [00:05<03:11, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 283M/10.0G [00:05<02:23, 67.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 294M/10.0G [00:06<04:04, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 315M/10.0G [00:06<04:04, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 336M/10.0G [00:06<03:01, 53.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   3%|▏    | 346M/10.0G [00:07<03:20, 48.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 367M/10.0G [00:07<02:48, 57.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 398M/10.0G [00:07<02:32, 62.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 419M/10.0G [00:08<02:30, 63.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   4%|▏    | 440M/10.0G [00:08<02:09, 74.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 451M/10.0G [00:08<02:36, 61.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 472M/10.0G [00:09<02:40, 59.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▏    | 482M/10.0G [00:09<02:27, 64.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 503M/10.0G [00:09<02:37, 60.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 524M/10.0G [00:10<02:43, 58.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   5%|▎    | 545M/10.0G [00:10<02:10, 72.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 556M/10.0G [00:10<02:32, 61.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 577M/10.0G [00:10<02:28, 63.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 608M/10.0G [00:11<02:22, 65.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   6%|▎    | 629M/10.0G [00:11<02:21, 66.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 661M/10.0G [00:12<02:40, 58.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 671M/10.0G [00:12<02:40, 58.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 682M/10.0G [00:12<03:05, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 703M/10.0G [00:12<02:19, 66.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 713M/10.0G [00:13<03:41, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   7%|▎    | 734M/10.0G [00:13<03:45, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 755M/10.0G [00:14<03:05, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 765M/10.0G [00:14<03:40, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 776M/10.0G [00:14<03:19, 46.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 786M/10.0G [00:15<03:32, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 797M/10.0G [00:15<03:05, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 818M/10.0G [00:15<02:50, 53.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 839M/10.0G [00:15<03:05, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   8%|▍    | 849M/10.0G [00:16<03:15, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 860M/10.0G [00:16<02:59, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 870M/10.0G [00:17<04:59, 30.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 891M/10.0G [00:17<04:27, 34.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 923M/10.0G [00:18<04:13, 35.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:   9%|▍    | 944M/10.0G [00:18<03:38, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍    | 965M/10.0G [00:18<02:52, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍    | 975M/10.0G [00:19<03:35, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍    | 996M/10.0G [00:19<03:08, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍   | 1.02G/10.0G [00:19<02:22, 63.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍   | 1.03G/10.0G [00:20<03:05, 48.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  10%|▍   | 1.05G/10.0G [00:20<02:42, 55.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.06G/10.0G [00:20<02:37, 56.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.08G/10.0G [00:21<02:41, 55.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.10G/10.0G [00:21<02:39, 55.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.12G/10.0G [00:21<02:09, 68.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  11%|▍   | 1.13G/10.0G [00:22<03:06, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.15G/10.0G [00:22<03:14, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.17G/10.0G [00:22<02:33, 57.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.18G/10.0G [00:23<03:18, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.20G/10.0G [00:23<03:03, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.21G/10.0G [00:23<03:43, 39.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.23G/10.0G [00:24<02:30, 58.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  12%|▍   | 1.24G/10.0G [00:24<03:07, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.26G/10.0G [00:24<02:41, 54.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.28G/10.0G [00:25<02:32, 57.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.29G/10.0G [00:25<02:53, 50.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.31G/10.0G [00:25<02:33, 56.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.32G/10.0G [00:25<02:18, 62.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.33G/10.0G [00:26<02:49, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  13%|▌   | 1.34G/10.0G [00:26<02:45, 52.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.36G/10.0G [00:26<02:31, 57.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.38G/10.0G [00:26<01:52, 76.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.39G/10.0G [00:26<02:10, 66.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.42G/10.0G [00:27<02:21, 60.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.44G/10.0G [00:27<01:51, 76.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  14%|▌   | 1.45G/10.0G [00:27<02:03, 69.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.47G/10.0G [00:27<01:52, 76.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.49G/10.0G [00:28<01:37, 87.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.50G/10.0G [00:28<02:12, 63.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.52G/10.0G [00:28<01:52, 75.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  15%|▌   | 1.53G/10.0G [00:28<02:29, 56.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▌   | 1.55G/10.0G [00:29<02:28, 56.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.57G/10.0G [00:29<02:36, 53.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.58G/10.0G [00:29<02:33, 55.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.60G/10.0G [00:30<02:35, 54.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.63G/10.0G [00:30<02:30, 55.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  16%|▋   | 1.65G/10.0G [00:30<02:02, 68.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.66G/10.0G [00:31<02:26, 57.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.68G/10.0G [00:31<02:20, 59.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.70G/10.0G [00:31<02:05, 66.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.71G/10.0G [00:32<02:54, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  17%|▋   | 1.73G/10.0G [00:32<02:55, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.75G/10.0G [00:32<02:18, 59.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.76G/10.0G [00:33<02:47, 49.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.78G/10.0G [00:33<02:43, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.81G/10.0G [00:33<02:16, 60.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  18%|▋   | 1.84G/10.0G [00:34<02:19, 58.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▋   | 1.86G/10.0G [00:34<01:54, 71.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▋   | 1.87G/10.0G [00:34<02:16, 59.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.89G/10.0G [00:35<03:00, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.91G/10.0G [00:35<02:16, 59.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.92G/10.0G [00:35<02:38, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  19%|▊   | 1.94G/10.0G [00:36<02:25, 55.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.96G/10.0G [00:36<01:52, 71.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.98G/10.0G [00:36<01:50, 72.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 1.99G/10.0G [00:36<02:11, 61.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 2.01G/10.0G [00:37<01:45, 75.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 2.02G/10.0G [00:37<02:22, 56.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  20%|▊   | 2.04G/10.0G [00:37<02:29, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.07G/10.0G [00:38<01:56, 68.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.08G/10.0G [00:38<02:44, 48.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.10G/10.0G [00:39<02:58, 44.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.13G/10.0G [00:39<02:21, 55.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  21%|▊   | 2.15G/10.0G [00:39<02:11, 59.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|▊   | 2.18G/10.0G [00:40<01:54, 68.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.20G/10.0G [00:40<01:56, 67.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  22%|▉   | 2.23G/10.0G [00:40<01:51, 69.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.25G/10.0G [00:41<02:13, 58.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.28G/10.0G [00:41<01:50, 70.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.29G/10.0G [00:41<02:10, 59.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.31G/10.0G [00:42<01:57, 65.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.33G/10.0G [00:42<01:33, 82.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  23%|▉   | 2.35G/10.0G [00:42<01:38, 77.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.36G/10.0G [00:42<02:02, 62.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.38G/10.0G [00:43<01:46, 71.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.39G/10.0G [00:43<02:38, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.41G/10.0G [00:43<02:24, 52.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.43G/10.0G [00:44<01:51, 67.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  24%|▉   | 2.44G/10.0G [00:44<01:57, 64.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|▉   | 2.46G/10.0G [00:44<02:13, 56.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|▉   | 2.49G/10.0G [00:44<01:48, 69.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|▉   | 2.50G/10.0G [00:45<03:11, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.51G/10.0G [00:45<02:45, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.52G/10.0G [00:46<03:00, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.53G/10.0G [00:46<02:32, 48.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.54G/10.0G [00:46<02:26, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  25%|█   | 2.55G/10.0G [00:46<03:16, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.57G/10.0G [00:47<04:06, 30.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.59G/10.0G [00:48<03:34, 34.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.60G/10.0G [00:48<03:47, 32.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.62G/10.0G [00:48<02:58, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  26%|█   | 2.64G/10.0G [00:49<02:55, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.65G/10.0G [00:49<03:25, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.66G/10.0G [00:50<03:18, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.67G/10.0G [00:50<03:37, 33.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.69G/10.0G [00:50<02:52, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.71G/10.0G [00:51<03:14, 37.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.73G/10.0G [00:51<02:57, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  27%|█   | 2.75G/10.0G [00:51<02:10, 55.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.76G/10.0G [00:52<02:36, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.78G/10.0G [00:52<02:24, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.80G/10.0G [00:52<02:03, 58.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█   | 2.81G/10.0G [00:52<02:00, 59.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█▏  | 2.83G/10.0G [00:53<02:32, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  28%|█▏  | 2.84G/10.0G [00:53<02:27, 48.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.85G/10.0G [00:53<02:13, 53.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.86G/10.0G [00:54<02:24, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.88G/10.0G [00:54<01:55, 61.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.90G/10.0G [00:54<01:28, 79.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.92G/10.0G [00:54<01:49, 65.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  29%|█▏  | 2.94G/10.0G [00:55<02:10, 54.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.96G/10.0G [00:55<02:02, 57.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.97G/10.0G [00:55<01:55, 60.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.98G/10.0G [00:55<01:48, 64.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 2.99G/10.0G [00:55<01:47, 65.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 3.01G/10.0G [00:56<01:55, 60.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 3.02G/10.0G [00:56<01:59, 58.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  30%|█▏  | 3.04G/10.0G [00:56<02:14, 51.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.05G/10.0G [00:57<02:03, 56.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.06G/10.0G [00:57<02:07, 54.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.07G/10.0G [00:57<02:03, 56.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.08G/10.0G [00:57<01:57, 58.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.09G/10.0G [00:57<02:12, 52.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▏  | 3.11G/10.0G [00:58<01:39, 69.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▎  | 3.12G/10.0G [00:58<01:43, 66.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  31%|█▎  | 3.15G/10.0G [00:58<02:24, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.17G/10.0G [00:59<02:04, 54.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.18G/10.0G [00:59<02:02, 55.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.20G/10.0G [00:59<01:49, 62.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.22G/10.0G [00:59<01:43, 65.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.23G/10.0G [01:00<01:41, 66.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  32%|█▎  | 3.24G/10.0G [01:00<01:44, 64.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.25G/10.0G [01:00<02:06, 53.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.27G/10.0G [01:00<01:36, 69.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.28G/10.0G [01:00<01:44, 64.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.29G/10.0G [01:01<01:42, 65.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.30G/10.0G [01:01<01:50, 60.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.32G/10.0G [01:01<01:26, 77.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.33G/10.0G [01:01<01:34, 70.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  33%|█▎  | 3.34G/10.0G [01:01<01:26, 77.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.36G/10.0G [01:02<02:44, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.37G/10.0G [01:02<02:21, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.38G/10.0G [01:02<02:02, 53.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.39G/10.0G [01:02<02:03, 53.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.40G/10.0G [01:02<02:03, 53.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.41G/10.0G [01:03<03:32, 31.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.42G/10.0G [01:03<03:17, 33.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▎  | 3.43G/10.0G [01:04<03:05, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  34%|█▍  | 3.44G/10.0G [01:04<03:47, 28.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.46G/10.0G [01:05<03:04, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.48G/10.0G [01:05<02:23, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.49G/10.0G [01:05<02:21, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.50G/10.0G [01:05<02:04, 52.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.51G/10.0G [01:06<02:38, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.53G/10.0G [01:06<02:09, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  35%|█▍  | 3.54G/10.0G [01:06<02:23, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.57G/10.0G [01:07<02:37, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.58G/10.0G [01:07<02:18, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.60G/10.0G [01:07<02:26, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.62G/10.0G [01:08<02:17, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.63G/10.0G [01:08<02:00, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  36%|█▍  | 3.65G/10.0G [01:09<02:42, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.66G/10.0G [01:09<02:30, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.67G/10.0G [01:10<03:55, 26.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.68G/10.0G [01:10<03:10, 33.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.70G/10.0G [01:10<02:48, 37.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.72G/10.0G [01:11<02:32, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  37%|█▍  | 3.74G/10.0G [01:11<02:11, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.75G/10.0G [01:11<02:08, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.77G/10.0G [01:12<01:54, 54.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.79G/10.0G [01:12<01:44, 59.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.80G/10.0G [01:12<02:07, 48.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.81G/10.0G [01:12<02:27, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.82G/10.0G [01:13<02:18, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.83G/10.0G [01:13<02:24, 42.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  38%|█▌  | 3.85G/10.0G [01:13<01:37, 63.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.86G/10.0G [01:13<01:35, 64.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.87G/10.0G [01:13<01:33, 65.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.88G/10.0G [01:14<01:52, 54.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.90G/10.0G [01:14<01:17, 78.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.91G/10.0G [01:14<01:26, 70.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.93G/10.0G [01:14<02:00, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  39%|█▌  | 3.94G/10.0G [01:15<01:52, 54.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.95G/10.0G [01:15<01:41, 59.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.96G/10.0G [01:15<02:12, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.97G/10.0G [01:15<01:58, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 3.98G/10.0G [01:15<01:59, 50.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 4.00G/10.0G [01:16<01:49, 55.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 4.02G/10.0G [01:16<01:45, 56.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 4.04G/10.0G [01:16<01:43, 57.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  40%|█▌  | 4.05G/10.0G [01:16<01:40, 59.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▌  | 4.06G/10.0G [01:17<01:57, 50.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.07G/10.0G [01:17<01:52, 52.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.09G/10.0G [01:17<02:02, 48.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.11G/10.0G [01:18<01:44, 56.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.12G/10.0G [01:18<02:15, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.13G/10.0G [01:18<01:57, 50.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  41%|█▋  | 4.14G/10.0G [01:19<02:16, 42.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.15G/10.0G [01:19<02:00, 48.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.16G/10.0G [01:19<02:04, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.17G/10.0G [01:19<02:02, 47.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.19G/10.0G [01:19<01:37, 59.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.20G/10.0G [01:19<01:30, 63.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.22G/10.0G [01:20<01:34, 61.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.23G/10.0G [01:20<01:36, 59.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  42%|█▋  | 4.25G/10.0G [01:20<02:03, 46.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.28G/10.0G [01:21<01:48, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.30G/10.0G [01:21<01:51, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.31G/10.0G [01:22<01:42, 55.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.32G/10.0G [01:22<01:32, 61.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.33G/10.0G [01:22<01:41, 55.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  43%|█▋  | 4.34G/10.0G [01:22<01:53, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▋  | 4.35G/10.0G [01:23<02:43, 34.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▋  | 4.36G/10.0G [01:23<02:15, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▋  | 4.37G/10.0G [01:23<02:00, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▊  | 4.38G/10.0G [01:23<02:03, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▊  | 4.39G/10.0G [01:23<01:46, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▊  | 4.40G/10.0G [01:24<02:24, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▊  | 4.41G/10.0G [01:24<01:58, 47.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▊  | 4.42G/10.0G [01:24<01:58, 46.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  44%|█▊  | 4.44G/10.0G [01:25<03:17, 28.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.46G/10.0G [01:25<02:51, 32.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.47G/10.0G [01:26<02:26, 37.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.48G/10.0G [01:26<02:13, 41.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.49G/10.0G [01:26<02:38, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.50G/10.0G [01:26<02:12, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.51G/10.0G [01:27<02:25, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.52G/10.0G [01:27<01:59, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.53G/10.0G [01:27<02:00, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  45%|█▊  | 4.54G/10.0G [01:27<02:01, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.56G/10.0G [01:28<02:13, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.58G/10.0G [01:28<01:41, 53.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.59G/10.0G [01:28<01:49, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.60G/10.0G [01:28<01:52, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.61G/10.0G [01:29<02:14, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.62G/10.0G [01:29<02:07, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.63G/10.0G [01:29<01:59, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  46%|█▊  | 4.65G/10.0G [01:30<02:00, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▊  | 4.66G/10.0G [01:30<01:52, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▊  | 4.67G/10.0G [01:30<02:06, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▊  | 4.68G/10.0G [01:30<01:44, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▉  | 4.69G/10.0G [01:30<02:00, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▉  | 4.70G/10.0G [01:31<01:55, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▉  | 4.71G/10.0G [01:31<01:59, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▉  | 4.72G/10.0G [01:31<02:28, 35.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▉  | 4.73G/10.0G [01:32<02:52, 30.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  47%|█▉  | 4.74G/10.0G [01:32<02:54, 30.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.75G/10.0G [01:33<03:16, 26.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.77G/10.0G [01:33<03:17, 26.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.78G/10.0G [01:34<02:41, 32.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.79G/10.0G [01:34<02:21, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.80G/10.0G [01:34<03:00, 28.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.81G/10.0G [01:35<03:14, 26.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.82G/10.0G [01:35<03:13, 26.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.83G/10.0G [01:35<02:57, 29.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  48%|█▉  | 4.84G/10.0G [01:36<02:27, 35.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.85G/10.0G [01:36<03:37, 23.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.87G/10.0G [01:37<03:13, 26.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.88G/10.0G [01:37<02:39, 32.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.89G/10.0G [01:37<02:17, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.90G/10.0G [01:37<02:48, 30.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.91G/10.0G [01:38<03:08, 26.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.92G/10.0G [01:38<02:46, 30.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.93G/10.0G [01:39<03:43, 22.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  49%|█▉  | 4.94G/10.0G [01:39<02:51, 29.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█▉  | 4.95G/10.0G [01:40<03:04, 27.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█▉  | 4.96G/10.0G [01:40<02:53, 29.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█▉  | 4.97G/10.0G [01:40<02:47, 29.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█▉  | 4.98G/10.0G [01:41<03:30, 23.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|█▉  | 4.99G/10.0G [01:41<02:51, 29.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|██  | 5.00G/10.0G [01:42<03:34, 23.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|██  | 5.02G/10.0G [01:42<02:05, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  50%|██  | 5.03G/10.0G [01:43<03:26, 24.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|██  | 5.05G/10.0G [01:43<02:42, 30.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|██  | 5.06G/10.0G [01:43<02:29, 33.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|██  | 5.09G/10.0G [01:44<02:05, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|██  | 5.11G/10.0G [01:44<02:14, 36.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  51%|██  | 5.14G/10.0G [01:45<02:01, 40.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|██  | 5.16G/10.0G [01:46<02:01, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|██  | 5.17G/10.0G [01:46<01:48, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|██  | 5.19G/10.0G [01:46<01:43, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|██  | 5.21G/10.0G [01:47<01:43, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  52%|██  | 5.24G/10.0G [01:47<01:39, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██  | 5.26G/10.0G [01:47<01:31, 52.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██  | 5.27G/10.0G [01:48<01:31, 51.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██  | 5.28G/10.0G [01:48<01:26, 54.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██  | 5.30G/10.0G [01:48<01:53, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██▏ | 5.32G/10.0G [01:49<01:58, 39.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██▏ | 5.34G/10.0G [01:49<01:27, 53.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  53%|██▏ | 5.35G/10.0G [01:49<01:47, 43.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.37G/10.0G [01:50<01:38, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.38G/10.0G [01:50<01:30, 51.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.39G/10.0G [01:50<01:41, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.40G/10.0G [01:51<01:51, 41.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.42G/10.0G [01:51<01:48, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  54%|██▏ | 5.44G/10.0G [01:51<01:17, 58.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|██▏ | 5.45G/10.0G [01:52<01:33, 48.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|██▏ | 5.47G/10.0G [01:52<01:28, 51.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|██▏ | 5.49G/10.0G [01:52<01:09, 64.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|██▏ | 5.51G/10.0G [01:53<01:33, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|██▏ | 5.53G/10.0G [01:53<01:38, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  55%|██▏ | 5.54G/10.0G [01:53<01:30, 49.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|██▏ | 5.56G/10.0G [01:54<01:49, 40.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|██▏ | 5.58G/10.0G [01:55<02:04, 35.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|██▏ | 5.60G/10.0G [01:55<01:31, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|██▏ | 5.61G/10.0G [01:55<01:53, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  56%|██▎ | 5.63G/10.0G [01:56<02:02, 35.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.65G/10.0G [01:56<01:27, 49.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.66G/10.0G [01:56<01:46, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.68G/10.0G [01:57<01:53, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.70G/10.0G [01:57<01:24, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.71G/10.0G [01:58<01:38, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  57%|██▎ | 5.74G/10.0G [01:58<01:30, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.76G/10.0G [01:58<01:07, 63.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.77G/10.0G [01:58<01:09, 60.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.78G/10.0G [01:58<01:10, 59.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.79G/10.0G [01:59<01:59, 35.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.81G/10.0G [01:59<01:23, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.82G/10.0G [02:00<01:40, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  58%|██▎ | 5.84G/10.0G [02:00<01:29, 46.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▎ | 5.86G/10.0G [02:00<01:08, 60.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▎ | 5.87G/10.0G [02:01<01:21, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▎ | 5.89G/10.0G [02:01<01:37, 41.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▎ | 5.91G/10.0G [02:01<01:17, 52.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▎ | 5.92G/10.0G [02:02<01:27, 46.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  59%|██▍ | 5.95G/10.0G [02:02<01:29, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██▍ | 5.97G/10.0G [02:02<01:10, 57.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██▍ | 5.98G/10.0G [02:03<01:35, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██▍ | 6.00G/10.0G [02:03<01:29, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██▍ | 6.02G/10.0G [02:03<01:05, 60.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██▍ | 6.03G/10.0G [02:04<01:29, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  60%|██▍ | 6.04G/10.0G [02:04<01:42, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.05G/10.0G [02:05<02:01, 32.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.07G/10.0G [02:05<01:23, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.08G/10.0G [02:05<01:28, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.09G/10.0G [02:06<01:25, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.10G/10.0G [02:06<01:57, 33.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.12G/10.0G [02:06<01:23, 46.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  61%|██▍ | 6.13G/10.0G [02:07<01:30, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██▍ | 6.16G/10.0G [02:07<01:43, 37.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██▍ | 6.18G/10.0G [02:08<01:23, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██▍ | 6.19G/10.0G [02:08<02:10, 29.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██▍ | 6.21G/10.0G [02:09<01:53, 33.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  62%|██▍ | 6.24G/10.0G [02:09<01:19, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.26G/10.0G [02:10<01:25, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.27G/10.0G [02:10<01:20, 46.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.28G/10.0G [02:10<01:21, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.29G/10.0G [02:11<01:37, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.31G/10.0G [02:11<01:37, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.33G/10.0G [02:12<01:42, 35.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  63%|██▌ | 6.34G/10.0G [02:12<01:43, 35.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.36G/10.0G [02:13<01:40, 36.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.38G/10.0G [02:13<01:29, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.39G/10.0G [02:13<01:16, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.40G/10.0G [02:13<01:37, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.42G/10.0G [02:14<01:37, 36.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.44G/10.0G [02:14<01:07, 52.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  64%|██▌ | 6.45G/10.0G [02:14<01:21, 43.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██▌ | 6.47G/10.0G [02:15<01:12, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██▌ | 6.48G/10.0G [02:15<01:05, 53.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██▌ | 6.50G/10.0G [02:15<01:09, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██▌ | 6.52G/10.0G [02:16<01:06, 52.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  65%|██▌ | 6.53G/10.0G [02:16<01:00, 57.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██▌ | 6.55G/10.0G [02:17<01:21, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██▋ | 6.57G/10.0G [02:17<01:20, 42.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██▋ | 6.60G/10.0G [02:17<01:00, 55.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██▋ | 6.61G/10.0G [02:18<01:29, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██▋ | 6.63G/10.0G [02:18<01:22, 41.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  66%|██▋ | 6.65G/10.0G [02:18<01:02, 54.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.66G/10.0G [02:19<01:10, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.68G/10.0G [02:19<01:14, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.70G/10.0G [02:19<00:58, 56.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.71G/10.0G [02:20<01:04, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  67%|██▋ | 6.73G/10.0G [02:21<01:25, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██▋ | 6.75G/10.0G [02:21<01:05, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██▋ | 6.76G/10.0G [02:21<01:11, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██▋ | 6.78G/10.0G [02:21<01:07, 47.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██▋ | 6.82G/10.0G [02:22<00:55, 57.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  68%|██▋ | 6.84G/10.0G [02:22<01:00, 52.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▋ | 6.87G/10.0G [02:23<01:10, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▊ | 6.89G/10.0G [02:24<01:11, 43.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▊ | 6.90G/10.0G [02:24<01:11, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▊ | 6.91G/10.0G [02:24<01:06, 46.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▊ | 6.92G/10.0G [02:25<01:23, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  69%|██▊ | 6.94G/10.0G [02:25<01:16, 39.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██▊ | 6.95G/10.0G [02:25<01:09, 43.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██▊ | 6.97G/10.0G [02:26<01:14, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██▊ | 6.99G/10.0G [02:26<01:17, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██▊ | 7.01G/10.0G [02:27<00:58, 51.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██▊ | 7.03G/10.0G [02:27<01:07, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  70%|██▊ | 7.05G/10.0G [02:27<01:04, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|██▊ | 7.08G/10.0G [02:28<00:59, 49.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|██▊ | 7.10G/10.0G [02:28<01:03, 45.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|██▊ | 7.12G/10.0G [02:29<00:51, 55.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  71%|██▊ | 7.13G/10.0G [02:30<01:24, 34.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▊ | 7.15G/10.0G [02:30<01:20, 35.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▊ | 7.17G/10.0G [02:30<01:03, 44.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▊ | 7.18G/10.0G [02:31<01:16, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▉ | 7.20G/10.0G [02:31<01:16, 36.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▉ | 7.22G/10.0G [02:32<01:01, 45.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▉ | 7.24G/10.0G [02:33<01:36, 28.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  72%|██▉ | 7.25G/10.0G [02:33<01:22, 33.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.26G/10.0G [02:33<01:38, 27.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.27G/10.0G [02:33<01:22, 33.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.28G/10.0G [02:34<01:10, 38.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.29G/10.0G [02:34<01:09, 39.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.30G/10.0G [02:34<00:59, 45.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.31G/10.0G [02:34<01:10, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.32G/10.0G [02:34<01:00, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.33G/10.0G [02:35<00:51, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  73%|██▉ | 7.34G/10.0G [02:35<00:52, 50.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.35G/10.0G [02:35<00:45, 57.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.36G/10.0G [02:35<00:57, 45.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.37G/10.0G [02:35<00:53, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.38G/10.0G [02:36<00:46, 56.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.39G/10.0G [02:36<01:24, 30.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.40G/10.0G [02:36<01:07, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.41G/10.0G [02:37<01:37, 26.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.43G/10.0G [02:37<00:59, 43.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  74%|██▉ | 7.44G/10.0G [02:38<01:12, 35.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|██▉ | 7.47G/10.0G [02:38<01:17, 32.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|██▉ | 7.48G/10.0G [02:38<01:07, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|██▉ | 7.49G/10.0G [02:39<00:56, 44.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|██▉ | 7.50G/10.0G [02:39<01:03, 39.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███ | 7.52G/10.0G [02:39<01:00, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  75%|███ | 7.54G/10.0G [02:40<00:44, 55.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.55G/10.0G [02:40<00:56, 43.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.57G/10.0G [02:41<01:00, 40.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.59G/10.0G [02:41<00:48, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.60G/10.0G [02:42<01:20, 29.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.61G/10.0G [02:42<01:09, 34.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.62G/10.0G [02:43<01:33, 25.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  76%|███ | 7.64G/10.0G [02:43<01:00, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███ | 7.65G/10.0G [02:43<01:07, 34.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███ | 7.68G/10.0G [02:44<01:06, 35.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███ | 7.70G/10.0G [02:44<00:46, 49.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███ | 7.71G/10.0G [02:44<00:56, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  77%|███ | 7.73G/10.0G [02:45<00:58, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███ | 7.76G/10.0G [02:45<00:46, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███ | 7.78G/10.0G [02:46<00:49, 44.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███ | 7.80G/10.0G [02:46<00:38, 57.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███▏| 7.81G/10.0G [02:47<00:51, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███▏| 7.83G/10.0G [02:47<01:03, 34.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  78%|███▏| 7.84G/10.0G [02:48<01:06, 32.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.85G/10.0G [02:48<00:59, 36.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.86G/10.0G [02:49<01:16, 27.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.87G/10.0G [02:49<01:06, 32.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.89G/10.0G [02:50<01:31, 23.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.91G/10.0G [02:50<00:55, 37.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.92G/10.0G [02:50<01:02, 33.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  79%|███▏| 7.94G/10.0G [02:51<01:06, 31.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 7.96G/10.0G [02:51<00:50, 40.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 7.97G/10.0G [02:52<00:58, 34.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 7.99G/10.0G [02:52<00:59, 33.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 8.01G/10.0G [02:53<00:50, 39.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 8.02G/10.0G [02:53<00:56, 34.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  80%|███▏| 8.04G/10.0G [02:54<00:59, 32.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▏| 8.06G/10.0G [02:54<00:49, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▏| 8.07G/10.0G [02:55<00:57, 33.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▏| 8.08G/10.0G [02:55<00:50, 38.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▏| 8.10G/10.0G [02:55<01:07, 28.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▏| 8.11G/10.0G [02:56<00:56, 33.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▎| 8.13G/10.0G [02:56<00:55, 33.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  81%|███▎| 8.15G/10.0G [02:57<00:47, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.16G/10.0G [02:57<00:42, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.17G/10.0G [02:57<00:36, 49.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.18G/10.0G [02:57<00:45, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.20G/10.0G [02:58<00:43, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.22G/10.0G [02:58<00:34, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.23G/10.0G [02:58<00:42, 41.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  82%|███▎| 8.24G/10.0G [02:59<00:37, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.25G/10.0G [02:59<00:39, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.27G/10.0G [02:59<00:26, 66.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.28G/10.0G [02:59<00:37, 45.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.29G/10.0G [03:00<00:35, 47.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.30G/10.0G [03:00<00:47, 35.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.33G/10.0G [03:00<00:32, 50.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.34G/10.0G [03:01<00:35, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  83%|███▎| 8.35G/10.0G [03:01<00:30, 53.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.36G/10.0G [03:01<00:41, 39.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.38G/10.0G [03:01<00:27, 59.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.39G/10.0G [03:02<00:31, 50.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.41G/10.0G [03:02<00:33, 47.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▎| 8.42G/10.0G [03:02<00:29, 54.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  84%|███▍| 8.44G/10.0G [03:03<00:34, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.46G/10.0G [03:03<00:34, 44.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.48G/10.0G [03:03<00:28, 52.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.49G/10.0G [03:04<00:32, 45.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.50G/10.0G [03:04<00:28, 51.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.51G/10.0G [03:04<00:38, 38.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.54G/10.0G [03:05<00:26, 56.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  85%|███▍| 8.55G/10.0G [03:05<00:30, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.57G/10.0G [03:05<00:32, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.59G/10.0G [03:06<00:27, 50.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.60G/10.0G [03:06<00:40, 34.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.61G/10.0G [03:07<00:37, 37.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.62G/10.0G [03:07<00:46, 29.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  86%|███▍| 8.64G/10.0G [03:07<00:33, 40.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.65G/10.0G [03:08<00:35, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.67G/10.0G [03:08<00:32, 40.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.68G/10.0G [03:08<00:31, 42.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.69G/10.0G [03:09<00:29, 44.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.70G/10.0G [03:09<00:33, 38.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.72G/10.0G [03:09<00:31, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  87%|███▍| 8.75G/10.0G [03:10<00:22, 56.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.76G/10.0G [03:11<00:41, 30.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.77G/10.0G [03:11<00:35, 34.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.78G/10.0G [03:11<00:46, 26.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.79G/10.0G [03:12<00:38, 31.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.80G/10.0G [03:12<00:34, 35.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.81G/10.0G [03:12<00:36, 32.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  88%|███▌| 8.83G/10.0G [03:13<00:37, 30.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.85G/10.0G [03:13<00:25, 45.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.86G/10.0G [03:13<00:29, 38.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.88G/10.0G [03:14<00:29, 37.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.89G/10.0G [03:14<00:28, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.90G/10.0G [03:14<00:24, 44.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.91G/10.0G [03:15<00:26, 41.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  89%|███▌| 8.93G/10.0G [03:15<00:28, 36.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 8.95G/10.0G [03:15<00:19, 53.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 8.97G/10.0G [03:16<00:27, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 8.99G/10.0G [03:17<00:32, 31.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 9.01G/10.0G [03:17<00:23, 42.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 9.02G/10.0G [03:18<00:29, 32.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  90%|███▌| 9.04G/10.0G [03:18<00:27, 34.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▌| 9.06G/10.0G [03:18<00:19, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▋| 9.07G/10.0G [03:19<00:20, 46.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▋| 9.09G/10.0G [03:19<00:19, 47.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▋| 9.11G/10.0G [03:19<00:14, 61.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▋| 9.12G/10.0G [03:20<00:20, 43.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  91%|███▋| 9.14G/10.0G [03:20<00:20, 40.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.15G/10.0G [03:20<00:19, 44.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.16G/10.0G [03:20<00:16, 50.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.18G/10.0G [03:21<00:21, 37.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.20G/10.0G [03:21<00:20, 39.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.21G/10.0G [03:22<00:17, 44.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.22G/10.0G [03:22<00:19, 40.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  92%|███▋| 9.23G/10.0G [03:22<00:20, 38.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.25G/10.0G [03:23<00:19, 38.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.27G/10.0G [03:24<00:25, 28.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.28G/10.0G [03:24<00:22, 31.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.30G/10.0G [03:24<00:18, 38.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.32G/10.0G [03:25<00:15, 42.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.33G/10.0G [03:25<00:14, 47.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  93%|███▋| 9.34G/10.0G [03:25<00:13, 49.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▋| 9.35G/10.0G [03:26<00:16, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▊| 9.37G/10.0G [03:26<00:15, 40.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▊| 9.38G/10.0G [03:26<00:14, 43.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▊| 9.41G/10.0G [03:27<00:14, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▊| 9.43G/10.0G [03:27<00:14, 38.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  94%|███▊| 9.45G/10.0G [03:28<00:11, 47.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.46G/10.0G [03:28<00:13, 41.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.47G/10.0G [03:28<00:11, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.48G/10.0G [03:29<00:15, 32.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.51G/10.0G [03:29<00:12, 38.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.53G/10.0G [03:30<00:11, 41.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  95%|███▊| 9.54G/10.0G [03:30<00:11, 41.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.56G/10.0G [03:30<00:09, 47.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.58G/10.0G [03:31<00:08, 47.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.59G/10.0G [03:31<00:07, 52.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.60G/10.0G [03:31<00:06, 57.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.62G/10.0G [03:32<00:14, 27.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.64G/10.0G [03:33<00:13, 26.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  96%|███▊| 9.65G/10.0G [03:33<00:11, 30.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▊| 9.66G/10.0G [03:33<00:09, 34.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▊| 9.67G/10.0G [03:34<00:10, 31.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▊| 9.68G/10.0G [03:34<00:09, 35.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▉| 9.69G/10.0G [03:34<00:08, 36.1MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▉| 9.71G/10.0G [03:34<00:05, 55.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▉| 9.72G/10.0G [03:35<00:08, 31.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  97%|███▉| 9.74G/10.0G [03:36<00:06, 36.9MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.76G/10.0G [03:36<00:04, 51.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.77G/10.0G [03:36<00:05, 43.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.78G/10.0G [03:36<00:04, 44.3MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.79G/10.0G [03:37<00:06, 32.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.81G/10.0G [03:37<00:03, 48.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.83G/10.0G [03:37<00:04, 41.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.84G/10.0G [03:37<00:03, 46.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  98%|███▉| 9.85G/10.0G [03:38<00:05, 30.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|███▉| 9.87G/10.0G [03:38<00:02, 45.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|███▉| 9.88G/10.0G [03:39<00:03, 37.7MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|███▉| 9.90G/10.0G [03:39<00:02, 33.8MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|███▉| 9.92G/10.0G [03:40<00:01, 42.4MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin:  99%|███▉| 9.93G/10.0G [03:40<00:01, 36.5MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|███▉| 9.95G/10.0G [03:41<00:01, 37.0MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|███▉| 9.96G/10.0G [03:41<00:00, 39.6MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|███▉| 9.98G/10.0G [03:41<00:00, 42.2MB/s]\u001b[A\n",
      "pytorch_model-00001-of-00002.bin: 100%|████| 10.0G/10.0G [03:42<00:00, 45.0MB/s]\u001b[A\n",
      "Downloading shards:  50%|████████████            | 1/2 [03:42<03:42, 222.38s/it]\n",
      "pytorch_model-00002-of-00002.bin:   0%|             | 0.00/2.18G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   1%|     | 21.0M/2.18G [00:00<00:11, 188MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   2%|     | 41.9M/2.18G [00:00<00:18, 113MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   3%|    | 62.9M/2.18G [00:00<00:21, 98.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   4%|▏   | 83.9M/2.18G [00:00<00:24, 86.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   5%|▏    | 105M/2.18G [00:01<00:23, 89.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   6%|▎    | 136M/2.18G [00:01<00:23, 85.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   7%|▎    | 157M/2.18G [00:01<00:23, 87.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   8%|▍     | 178M/2.18G [00:01<00:19, 103MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:   9%|▍    | 199M/2.18G [00:02<00:24, 80.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  10%|▍    | 210M/2.18G [00:02<00:24, 81.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  11%|▌    | 241M/2.18G [00:02<00:19, 97.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  12%|▌    | 262M/2.18G [00:02<00:23, 81.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  13%|▋    | 283M/2.18G [00:03<00:20, 93.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 304M/2.18G [00:03<00:21, 87.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  14%|▋    | 315M/2.18G [00:03<00:23, 80.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 346M/2.18G [00:03<00:19, 94.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  16%|▊    | 357M/2.18G [00:03<00:21, 86.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  17%|▊    | 367M/2.18G [00:04<00:27, 66.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  18%|▉    | 388M/2.18G [00:04<00:20, 88.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  19%|▉    | 409M/2.18G [00:04<00:18, 93.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20%|▉    | 430M/2.18G [00:04<00:18, 92.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  20%|█    | 440M/2.18G [00:04<00:20, 86.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  21%|█▎    | 461M/2.18G [00:05<00:16, 102MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  22%|█    | 482M/2.18G [00:05<00:17, 98.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  23%|█▏   | 503M/2.18G [00:05<00:17, 94.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  24%|█▏   | 524M/2.18G [00:05<00:19, 84.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  25%|█▌    | 545M/2.18G [00:05<00:16, 101MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  26%|█▎   | 566M/2.18G [00:06<00:17, 92.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  27%|█▎   | 587M/2.18G [00:06<00:20, 78.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  28%|█▍   | 608M/2.18G [00:06<00:18, 83.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  29%|█▍   | 629M/2.18G [00:06<00:16, 95.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  30%|█▍   | 650M/2.18G [00:07<00:17, 87.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  31%|█▊    | 671M/2.18G [00:07<00:14, 102MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  32%|█▌   | 692M/2.18G [00:07<00:17, 83.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  33%|█▋   | 713M/2.18G [00:08<00:18, 80.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  34%|█▋   | 734M/2.18G [00:08<00:15, 91.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  35%|██    | 755M/2.18G [00:08<00:13, 104MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36%|█▊   | 776M/2.18G [00:08<00:16, 85.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  36%|█▊   | 786M/2.18G [00:08<00:17, 77.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  38%|█▉   | 818M/2.18G [00:09<00:16, 84.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  39%|█▉   | 839M/2.18G [00:09<00:18, 70.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40%|██   | 870M/2.18G [00:10<00:17, 74.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  40%|██   | 881M/2.18G [00:10<00:17, 75.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  41%|██   | 891M/2.18G [00:10<00:22, 58.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  42%|██   | 912M/2.18G [00:10<00:16, 76.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43%|██▏  | 933M/2.18G [00:11<00:19, 65.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  43%|██▏  | 944M/2.18G [00:11<00:23, 52.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  44%|██▏  | 965M/2.18G [00:11<00:17, 67.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45%|██▏  | 975M/2.18G [00:11<00:18, 66.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  45%|██▎  | 986M/2.18G [00:11<00:16, 71.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  46%|██▎  | 996M/2.18G [00:12<00:23, 50.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47%|█▊  | 1.02G/2.18G [00:12<00:20, 57.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  47%|█▉  | 1.03G/2.18G [00:12<00:21, 53.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  48%|█▉  | 1.05G/2.18G [00:12<00:17, 64.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  49%|█▉  | 1.07G/2.18G [00:13<00:13, 79.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  50%|██  | 1.09G/2.18G [00:13<00:11, 94.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  51%|██  | 1.11G/2.18G [00:13<00:18, 57.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52%|██  | 1.12G/2.18G [00:14<00:17, 59.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  52%|██  | 1.13G/2.18G [00:14<00:18, 55.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  53%|██  | 1.15G/2.18G [00:14<00:15, 66.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54%|██▏ | 1.17G/2.18G [00:14<00:13, 75.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  54%|██▏ | 1.18G/2.18G [00:14<00:14, 69.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  55%|██▏ | 1.21G/2.18G [00:15<00:15, 62.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  56%|██▎ | 1.23G/2.18G [00:15<00:12, 76.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  57%|██▎ | 1.24G/2.18G [00:15<00:12, 77.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58%|██▎ | 1.26G/2.18G [00:15<00:10, 86.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  58%|██▎ | 1.27G/2.18G [00:15<00:10, 88.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59%|██▎ | 1.28G/2.18G [00:16<00:12, 69.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  59%|██▎ | 1.29G/2.18G [00:16<00:12, 68.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60%|██▍ | 1.30G/2.18G [00:16<00:13, 62.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  60%|██▍ | 1.31G/2.18G [00:16<00:15, 54.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  61%|██▍ | 1.33G/2.18G [00:16<00:11, 71.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  62%|██▍ | 1.34G/2.18G [00:17<00:12, 67.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  63%|██▌ | 1.36G/2.18G [00:17<00:12, 62.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64%|██▌ | 1.38G/2.18G [00:17<00:10, 76.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  64%|██▌ | 1.39G/2.18G [00:17<00:11, 70.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  65%|██▌ | 1.42G/2.18G [00:18<00:09, 79.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  66%|██▋ | 1.44G/2.18G [00:18<00:07, 99.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  67%|██▋ | 1.46G/2.18G [00:18<00:07, 97.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  68%|██▋ | 1.48G/2.18G [00:18<00:10, 66.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  69%|██▊ | 1.50G/2.18G [00:19<00:09, 74.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  70%|██▊ | 1.52G/2.18G [00:19<00:08, 75.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  71%|██▊ | 1.55G/2.18G [00:19<00:06, 92.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  72%|██▉ | 1.57G/2.18G [00:19<00:06, 94.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  74%|██▉ | 1.60G/2.18G [00:20<00:05, 99.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  75%|██▉ | 1.63G/2.18G [00:20<00:05, 99.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  76%|███▊ | 1.65G/2.18G [00:20<00:04, 114MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  77%|███ | 1.67G/2.18G [00:20<00:05, 99.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  78%|███ | 1.69G/2.18G [00:21<00:05, 84.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  79%|███▏| 1.71G/2.18G [00:21<00:05, 93.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  80%|███▏| 1.73G/2.18G [00:21<00:05, 75.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81%|███▏| 1.75G/2.18G [00:21<00:04, 90.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  81%|███▎| 1.77G/2.18G [00:22<00:04, 93.6MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  82%|███▎| 1.79G/2.18G [00:22<00:05, 74.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  83%|███▎| 1.81G/2.18G [00:22<00:04, 72.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  84%|███▎| 1.84G/2.18G [00:23<00:05, 65.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  85%|███▍| 1.85G/2.18G [00:23<00:04, 68.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  86%|███▍| 1.87G/2.18G [00:23<00:04, 69.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  87%|███▍| 1.89G/2.18G [00:23<00:04, 70.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88%|███▌| 1.91G/2.18G [00:24<00:03, 79.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  88%|███▌| 1.92G/2.18G [00:24<00:03, 65.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  89%|███▌| 1.94G/2.18G [00:24<00:03, 70.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  90%|███▌| 1.96G/2.18G [00:24<00:02, 89.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  91%|███▋| 1.98G/2.18G [00:24<00:02, 88.2MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92%|███▋| 1.99G/2.18G [00:25<00:02, 63.5MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  92%|███▋| 2.00G/2.18G [00:25<00:02, 68.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  93%|███▋| 2.02G/2.18G [00:25<00:02, 62.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94%|███▊| 2.04G/2.18G [00:26<00:02, 57.7MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  94%|███▊| 2.06G/2.18G [00:26<00:01, 60.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  95%|███▊| 2.08G/2.18G [00:26<00:01, 66.4MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  96%|███▊| 2.10G/2.18G [00:26<00:01, 69.3MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  97%|███▉| 2.12G/2.18G [00:27<00:00, 84.9MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  98%|███▉| 2.13G/2.18G [00:27<00:00, 78.8MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99%|███▉| 2.15G/2.18G [00:27<00:00, 85.0MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin:  99%|███▉| 2.16G/2.18G [00:27<00:00, 71.1MB/s]\u001b[A\n",
      "pytorch_model-00002-of-00002.bin: 100%|████| 2.18G/2.18G [00:27<00:00, 78.1MB/s]\u001b[A\n",
      "Downloading shards: 100%|████████████████████████| 2/2 [04:10<00:00, 125.23s/it]\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [01:01<00:00, 30.55s/it]\n",
      "generation_config.json: 100%|███████████████████| 111/111 [00:00<00:00, 424kB/s]\n",
      "tokenizer_config.json: 100%|███████████████████| 677/677 [00:00<00:00, 2.48MB/s]\n",
      "vocab.json: 100%|████████████████████████████| 777k/777k [00:00<00:00, 24.4MB/s]\n",
      "merges.txt: 100%|████████████████████████████| 442k/442k [00:00<00:00, 47.3MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 2.06M/2.06M [00:00<00:00, 23.3MB/s]\n",
      "special_tokens_map.json: 100%|█████████████████| 532/532 [00:00<00:00, 2.39MB/s]\n",
      "2024-03-28:16:41:50,794 WARNING  [task.py:322] [Task: bigbench_code_line_description_generate_until] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-03-28:16:41:50,795 WARNING  [task.py:322] [Task: bigbench_code_line_description_generate_until] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-03-28:16:41:50,801 INFO     [task.py:395] Building contexts for bigbench_code_line_description_generate_until on rank 0...\n",
      "100%|████████████████████████████████████████| 60/60 [00:00<00:00, 91478.82it/s]\n",
      "2024-03-28:16:41:50,805 INFO     [evaluator.py:379] Running generate_until requests\n",
      "Running generate_until requests:   0%|                   | 0/60 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
      "Determined Largest batch size: 1\n",
      "Running generate_until requests: 100%|██████████| 60/60 [01:29<00:00,  1.49s/it]\n",
      "hf (pretrained=bigcode/starcoderbase-3b,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto\n",
      "|                    Tasks                    |Version|Filter|n-shot|  Metric   |Value|   |Stderr|\n",
      "|---------------------------------------------|------:|------|-----:|-----------|----:|---|-----:|\n",
      "|bigbench_code_line_description_generate_until|      1|none  |     0|exact_match|    0|±  |     0|\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        bigbench_code_line_description_generate_until/exact_match ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bigbench_code_line_description_generate_until/exact_match_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              bigbench_code_line_description_generate_until/alias bigbench_code_line_d...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        bigbench_code_line_description_generate_until/exact_match 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bigbench_code_line_description_generate_until/exact_match_stderr 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfragrant-planet-17\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai/runs/q91q4rp5/workspace\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 2 media file(s), 3 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240328_163624-q91q4rp5/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=bigcode/starcoderbase-3b,trust_remote_code=True \\\n",
    "    --tasks bigbench_code_line_description_generate_until \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto \\\n",
    "    --output_path output/starcoderbase-3b \\\n",
    "    --wandb_args project=llm_eval_benchmark_lightning_ai \\\n",
    "    --log_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Benchmark] bigbench_code_line_description_multiple_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcosmo3769\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/teamspace/studios/this_studio/lm-evaluation-harness/wandb/run-20240328_164405-zfbkj4ez\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdainty-disco-18\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai/runs/zfbkj4ez/workspace\u001b[0m\n",
      "2024-03-28:16:44:09,509 INFO     [__main__.py:251] Verbosity set to INFO\n",
      "2024-03-28:16:44:14,892 WARNING  [__main__.py:316] File output/starcoderbase-3b/results.json already exists. Results will be overwritten.\n",
      "2024-03-28:16:44:14,893 INFO     [__main__.py:335] Selected Tasks: ['bigbench_code_line_description_multiple_choice']\n",
      "2024-03-28:16:44:14,894 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-03-28:16:44:14,894 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'bigcode/starcoderbase-3b', 'trust_remote_code': True}\n",
      "2024-03-28:16:44:14,940 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:51<00:00, 25.98s/it]\n",
      "2024-03-28:16:45:07,401 WARNING  [task.py:763] [Task: bigbench_code_line_description_multiple_choice] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-03-28:16:45:07,401 WARNING  [task.py:775] [Task: bigbench_code_line_description_multiple_choice] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-03-28:16:45:09,990 WARNING  [task.py:322] [Task: bigbench_code_line_description_multiple_choice] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-03-28:16:45:09,990 WARNING  [task.py:322] [Task: bigbench_code_line_description_multiple_choice] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-03-28:16:45:09,997 INFO     [task.py:395] Building contexts for bigbench_code_line_description_multiple_choice on rank 0...\n",
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 2397.00it/s]\n",
      "2024-03-28:16:45:10,026 INFO     [evaluator.py:379] Running loglikelihood requests\n",
      "Running loglikelihood requests:   0%|                   | 0/242 [00:00<?, ?it/s]Passed argument batch_size = auto:1. Detecting largest batch size\n",
      "Determined largest batch size: 16\n",
      "Running loglikelihood requests: 100%|█████████| 242/242 [01:03<00:00,  3.80it/s]\n",
      "hf (pretrained=bigcode/starcoderbase-3b,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (16)\n",
      "|                    Tasks                     |Version|Filter|n-shot|Metric|Value|   |Stderr|\n",
      "|----------------------------------------------|------:|------|-----:|------|----:|---|-----:|\n",
      "|bigbench_code_line_description_multiple_choice|      0|none  |     0|acc   | 0.25|±  |0.0564|\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        bigbench_code_line_description_multiple_choice/acc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bigbench_code_line_description_multiple_choice/acc_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        bigbench_code_line_description_multiple_choice/acc 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bigbench_code_line_description_multiple_choice/acc_stderr 0.05637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      bigbench_code_line_description_multiple_choice/alias bigbench_code_line_d...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdainty-disco-18\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai/runs/zfbkj4ez/workspace\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 2 media file(s), 4 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240328_164405-zfbkj4ez/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=bigcode/starcoderbase-3b,trust_remote_code=True \\\n",
    "    --tasks bigbench_code_line_description_multiple_choice \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto \\\n",
    "    --output_path output/starcoderbase-3b \\\n",
    "    --wandb_args project=llm_eval_benchmark_lightning_ai \\\n",
    "    --log_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Benchmark] codexglue_code2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcosmo3769\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/teamspace/studios/this_studio/lm-evaluation-harness/wandb/run-20240328_165010-x7s2yo9e\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdrawn-dream-19\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai/runs/x7s2yo9e/workspace\u001b[0m\n",
      "2024-03-28:16:50:14,857 INFO     [__main__.py:251] Verbosity set to INFO\n",
      "2024-03-28:16:50:20,234 WARNING  [__main__.py:266]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2024-03-28:16:50:20,236 WARNING  [__main__.py:316] File output/starcoderbase-3b/results.json already exists. Results will be overwritten.\n",
      "2024-03-28:16:50:20,236 INFO     [__main__.py:335] Selected Tasks: ['codexglue_code2text']\n",
      "2024-03-28:16:50:20,237 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-03-28:16:50:20,237 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'bigcode/starcoderbase-3b', 'trust_remote_code': True}\n",
      "2024-03-28:16:50:20,285 INFO     [huggingface.py:163] Using device 'cuda:0'\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.14s/it]\n",
      "2024-03-28:16:53:34,223 INFO     [task.py:395] Building contexts for code2text_javascript on rank 0...\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 10894.30it/s]\n",
      "2024-03-28:16:53:34,225 INFO     [task.py:395] Building contexts for code2text_python on rank 0...\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 13210.41it/s]\n",
      "2024-03-28:16:53:34,226 INFO     [task.py:395] Building contexts for code2text_go on rank 0...\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 13865.47it/s]\n",
      "2024-03-28:16:53:34,227 INFO     [task.py:395] Building contexts for code2text_php on rank 0...\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 13127.71it/s]\n",
      "2024-03-28:16:53:34,228 INFO     [task.py:395] Building contexts for code2text_ruby on rank 0...\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 13294.15it/s]\n",
      "2024-03-28:16:53:34,230 INFO     [task.py:395] Building contexts for code2text_java on rank 0...\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 14074.85it/s]\n",
      "2024-03-28:16:53:34,231 INFO     [evaluator.py:379] Running generate_until requests\n",
      "Running generate_until requests:   0%|                   | 0/12 [00:00<?, ?it/s]Passed argument batch_size = auto. Detecting largest batch size\n",
      "Determined Largest batch size: 1\n",
      "Running generate_until requests: 100%|██████████| 12/12 [03:16<00:00, 16.42s/it]\n",
      "2024-03-28:16:56:55,569 INFO     [__main__.py:383] Logging to Weights and Biases failed due to 'def smoothed_bleu_4(references, predictions, **kwargs):\\n    predictionMap = {}\\n    goldMap = {}\\n\\n    for rid, pred in enumerate(predictions):\\n        predictionMap[rid] = [splitPuncts(pred.strip().lower())]\\n\\n    for rid, row in enumerate(references):\\n        goldMap[rid] = [splitPuncts(row.strip().lower())]\\n\\n    return bleuFromMaps(goldMap, predictionMap)[0]\\n'\n",
      "hf (pretrained=bigcode/starcoderbase-3b,trust_remote_code=True), gen_kwargs: (None), limit: 2.0, num_fewshot: None, batch_size: auto\n",
      "|         Tasks         |Version|Filter|n-shot|    Metric     |Value |   |Stderr|\n",
      "|-----------------------|-------|------|-----:|---------------|-----:|---|-----:|\n",
      "|codexglue_code2text    |N/A    |none  |     0|smoothed_bleu_4|1.3519|±  |0.3067|\n",
      "| - code2text_go        |      1|none  |     0|smoothed_bleu_4|1.5781|±  |0.3734|\n",
      "| - code2text_java      |      1|none  |     0|smoothed_bleu_4|1.2778|±  |0.1991|\n",
      "| - code2text_javascript|      1|none  |     0|smoothed_bleu_4|1.1443|±  |0.1181|\n",
      "| - code2text_php       |      1|none  |     0|smoothed_bleu_4|0.5171|±  |0.5171|\n",
      "| - code2text_python    |      1|none  |     0|smoothed_bleu_4|2.8338|±  |1.5323|\n",
      "| - code2text_ruby      |      3|none  |     0|smoothed_bleu_4|0.7601|±  |0.7601|\n",
      "\n",
      "|      Groups       |Version|Filter|n-shot|    Metric     |Value |   |Stderr|\n",
      "|-------------------|-------|------|-----:|---------------|-----:|---|-----:|\n",
      "|codexglue_code2text|N/A    |none  |     0|smoothed_bleu_4|1.3519|±  |0.3067|\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                code2text_go/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         code2text_go/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              code2text_java/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       code2text_java/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        code2text_javascript/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: code2text_javascript/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               code2text_php/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        code2text_php/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            code2text_python/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     code2text_python/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              code2text_ruby/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       code2text_ruby/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         codexglue_code2text/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  codexglue_code2text/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          code2text_go/alias  - code2text_go\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                code2text_go/smoothed_bleu_4 1.57808\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         code2text_go/smoothed_bleu_4_stderr 0.3734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        code2text_java/alias  - code2text_java\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              code2text_java/smoothed_bleu_4 1.27781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       code2text_java/smoothed_bleu_4_stderr 0.19913\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  code2text_javascript/alias  - code2text_javascr...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        code2text_javascript/smoothed_bleu_4 1.14433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: code2text_javascript/smoothed_bleu_4_stderr 0.11813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         code2text_php/alias  - code2text_php\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               code2text_php/smoothed_bleu_4 0.51713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        code2text_php/smoothed_bleu_4_stderr 0.51713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      code2text_python/alias  - code2text_python\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            code2text_python/smoothed_bleu_4 2.83383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     code2text_python/smoothed_bleu_4_stderr 1.53227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        code2text_ruby/alias  - code2text_ruby\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              code2text_ruby/smoothed_bleu_4 0.76007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       code2text_ruby/smoothed_bleu_4_stderr 0.76007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   codexglue_code2text/alias codexglue_code2text\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         codexglue_code2text/smoothed_bleu_4 1.35187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  codexglue_code2text/smoothed_bleu_4_stderr 0.30669\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdrawn-dream-19\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai/runs/x7s2yo9e/workspace\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 2 media file(s), 3 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240328_165010-x7s2yo9e/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!lm_eval \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=bigcode/starcoderbase-3b,trust_remote_code=True \\\n",
    "    --tasks codexglue_code2text \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto \\\n",
    "    --output_path output/starcoderbase-3b \\\n",
    "    --limit 2 \\\n",
    "    --wandb_args project=llm_eval_benchmark_lightning_ai \\\n",
    "    --log_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run evaluations on starcoderbase-3b quantized model [GGUF]\n",
    "\n",
    "[HuggingFace Model card for starcoderbase-3b-GGUF](https://huggingface.co/cosmo3769/starcoderbase-3b-GGUF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running evaluation on quantized model [GGUF], run this in terminal to host your quantized model locally using llama-cpp-python server.\n",
    "\n",
    "`python3 -m llama_cpp.server --model starcoderbase-3b/starcoderbase-3b.Q4_K_M.gguf --n_gpu_layers 10`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Benchmark] bigbench_code_line_description_generate_until"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 5.67k/5.67k [00:00<00:00, 18.8MB/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcosmo3769\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/teamspace/studios/this_studio/lm-evaluation-harness/wandb/run-20240328_154353-7929vc7b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mblooming-plant-14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai/runs/7929vc7b/workspace\u001b[0m\n",
      "2024-03-28:15:43:57,691 INFO     [__main__.py:251] Verbosity set to INFO\n",
      "2024-03-28:15:44:02,942 INFO     [__main__.py:335] Selected Tasks: ['bigbench_code_line_description_generate_until']\n",
      "2024-03-28:15:44:02,945 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-03-28:15:44:02,945 INFO     [evaluator.py:177] Initializing gguf model, with arguments: {'base_url': 'http://localhost:8000'}\n",
      "Downloading readme: 100%|████████████████████| 130k/130k [00:00<00:00, 28.0MB/s]\n",
      "Downloading data: 100%|█████████████████████| 17.8k/17.8k [00:00<00:00, 180kB/s]\n",
      "Downloading data: 100%|█████████████████████| 15.3k/15.3k [00:00<00:00, 173kB/s]\n",
      "Downloading data: 100%|█████████████████████| 9.25k/9.25k [00:00<00:00, 118kB/s]\n",
      "Generating default split: 100%|████████| 60/60 [00:00<00:00, 2874.25 examples/s]\n",
      "Generating train split: 100%|█████████| 44/44 [00:00<00:00, 19379.33 examples/s]\n",
      "Generating validation split: 100%|█████| 16/16 [00:00<00:00, 8200.01 examples/s]\n",
      "2024-03-28:15:44:06,052 WARNING  [task.py:322] [Task: bigbench_code_line_description_generate_until] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-03-28:15:44:06,052 WARNING  [task.py:322] [Task: bigbench_code_line_description_generate_until] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-03-28:15:44:06,059 INFO     [task.py:395] Building contexts for bigbench_code_line_description_generate_until on rank 0...\n",
      "100%|████████████████████████████████████████| 60/60 [00:00<00:00, 81786.88it/s]\n",
      "2024-03-28:15:44:06,064 INFO     [evaluator.py:379] Running generate_until requests\n",
      "100%|███████████████████████████████████████████| 60/60 [06:03<00:00,  6.07s/it]\n",
      "gguf (base_url=http://localhost:8000), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto\n",
      "|                    Tasks                    |Version|Filter|n-shot|  Metric   |Value|   |Stderr|\n",
      "|---------------------------------------------|------:|------|-----:|-----------|----:|---|-----:|\n",
      "|bigbench_code_line_description_generate_until|      1|none  |     0|exact_match|    0|±  |     0|\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        bigbench_code_line_description_generate_until/exact_match ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bigbench_code_line_description_generate_until/exact_match_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              bigbench_code_line_description_generate_until/alias bigbench_code_line_d...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        bigbench_code_line_description_generate_until/exact_match 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bigbench_code_line_description_generate_until/exact_match_stderr 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mblooming-plant-14\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai/runs/7929vc7b/workspace\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 2 media file(s), 4 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240328_154353-7929vc7b/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!lm_eval \\\n",
    "    --model gguf \\\n",
    "    --model_args base_url=http://localhost:8000 \\\n",
    "    --tasks bigbench_code_line_description_generate_until \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto \\\n",
    "    --output_path output/starcoderbase-3b-GGUF \\\n",
    "    --wandb_args project=llm_eval_benchmark_lightning_ai \\\n",
    "    --log_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Benchmark] bigbench_code_line_description_multiple_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcosmo3769\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/teamspace/studios/this_studio/lm-evaluation-harness/wandb/run-20240328_155229-jikk5396\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmisunderstood-bush-15\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai/runs/jikk5396/workspace\u001b[0m\n",
      "2024-03-28:15:52:33,503 INFO     [__main__.py:251] Verbosity set to INFO\n",
      "2024-03-28:15:52:38,852 WARNING  [__main__.py:316] File output/starcoderbase-3b-GGUF/results.json already exists. Results will be overwritten.\n",
      "2024-03-28:15:52:38,852 INFO     [__main__.py:335] Selected Tasks: ['bigbench_code_line_description_multiple_choice']\n",
      "2024-03-28:15:52:38,853 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-03-28:15:52:38,853 INFO     [evaluator.py:177] Initializing gguf model, with arguments: {'base_url': 'http://localhost:8000'}\n",
      "2024-03-28:15:52:38,855 WARNING  [task.py:763] [Task: bigbench_code_line_description_multiple_choice] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-03-28:15:52:38,855 WARNING  [task.py:775] [Task: bigbench_code_line_description_multiple_choice] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-03-28:15:52:41,199 WARNING  [task.py:322] [Task: bigbench_code_line_description_multiple_choice] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-03-28:15:52:41,199 WARNING  [task.py:322] [Task: bigbench_code_line_description_multiple_choice] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-03-28:15:52:41,206 INFO     [task.py:395] Building contexts for bigbench_code_line_description_multiple_choice on rank 0...\n",
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 2435.41it/s]\n",
      "2024-03-28:15:52:41,234 INFO     [evaluator.py:379] Running loglikelihood requests\n",
      "100%|█████████████████████████████████████████| 242/242 [27:52<00:00,  6.91s/it]\n",
      "gguf (base_url=http://localhost:8000), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto\n",
      "|                    Tasks                     |Version|Filter|n-shot|Metric|Value |   |Stderr|\n",
      "|----------------------------------------------|------:|------|-----:|------|-----:|---|-----:|\n",
      "|bigbench_code_line_description_multiple_choice|      0|none  |     0|acc   |0.2667|±  |0.0576|\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        bigbench_code_line_description_multiple_choice/acc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bigbench_code_line_description_multiple_choice/acc_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        bigbench_code_line_description_multiple_choice/acc 0.26667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: bigbench_code_line_description_multiple_choice/acc_stderr 0.05757\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      bigbench_code_line_description_multiple_choice/alias bigbench_code_line_d...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmisunderstood-bush-15\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai/runs/jikk5396/workspace\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 2 media file(s), 4 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240328_155229-jikk5396/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!lm_eval \\\n",
    "    --model gguf \\\n",
    "    --model_args base_url=http://localhost:8000 \\\n",
    "    --tasks bigbench_code_line_description_multiple_choice \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto \\\n",
    "    --output_path output/starcoderbase-3b-GGUF \\\n",
    "    --wandb_args project=llm_eval_benchmark_lightning_ai \\\n",
    "    --log_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Benchmark] codexglue_code2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcosmo3769\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/teamspace/studios/this_studio/lm-evaluation-harness/wandb/run-20240328_170043-8b8ucxhd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mearnest-armadillo-20\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai/runs/8b8ucxhd/workspace\u001b[0m\n",
      "2024-03-28:17:00:47,729 INFO     [__main__.py:251] Verbosity set to INFO\n",
      "2024-03-28:17:00:53,035 WARNING  [__main__.py:266]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.\n",
      "2024-03-28:17:00:53,036 WARNING  [__main__.py:316] File output/starcoderbase-3b-GGUF/results.json already exists. Results will be overwritten.\n",
      "2024-03-28:17:00:53,036 INFO     [__main__.py:335] Selected Tasks: ['codexglue_code2text']\n",
      "2024-03-28:17:00:53,037 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-03-28:17:00:53,038 INFO     [evaluator.py:177] Initializing gguf model, with arguments: {'base_url': 'http://localhost:8000'}\n",
      "2024-03-28:17:03:52,705 INFO     [task.py:395] Building contexts for code2text_javascript on rank 0...\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 11798.32it/s]\n",
      "2024-03-28:17:03:52,707 INFO     [task.py:395] Building contexts for code2text_python on rank 0...\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 14098.50it/s]\n",
      "2024-03-28:17:03:52,708 INFO     [task.py:395] Building contexts for code2text_go on rank 0...\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 14051.27it/s]\n",
      "2024-03-28:17:03:52,709 INFO     [task.py:395] Building contexts for code2text_php on rank 0...\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 13231.24it/s]\n",
      "2024-03-28:17:03:52,710 INFO     [task.py:395] Building contexts for code2text_ruby on rank 0...\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 12052.60it/s]\n",
      "2024-03-28:17:03:52,712 INFO     [task.py:395] Building contexts for code2text_java on rank 0...\n",
      "100%|██████████████████████████████████████████| 2/2 [00:00<00:00, 11351.30it/s]\n",
      "2024-03-28:17:03:52,713 INFO     [evaluator.py:379] Running generate_until requests\n",
      "100%|███████████████████████████████████████████| 12/12 [01:57<00:00,  9.76s/it]\n",
      "2024-03-28:17:05:54,422 INFO     [__main__.py:383] Logging to Weights and Biases failed due to 'def smoothed_bleu_4(references, predictions, **kwargs):\\n    predictionMap = {}\\n    goldMap = {}\\n\\n    for rid, pred in enumerate(predictions):\\n        predictionMap[rid] = [splitPuncts(pred.strip().lower())]\\n\\n    for rid, row in enumerate(references):\\n        goldMap[rid] = [splitPuncts(row.strip().lower())]\\n\\n    return bleuFromMaps(goldMap, predictionMap)[0]\\n'\n",
      "gguf (base_url=http://localhost:8000), gen_kwargs: (None), limit: 2.0, num_fewshot: None, batch_size: auto\n",
      "|         Tasks         |Version|Filter|n-shot|    Metric     | Value |   |Stderr|\n",
      "|-----------------------|-------|------|-----:|---------------|------:|---|-----:|\n",
      "|codexglue_code2text    |N/A    |none  |     0|smoothed_bleu_4| 4.9270|±  |1.1091|\n",
      "| - code2text_go        |      1|none  |     0|smoothed_bleu_4|11.3772|±  |2.3840|\n",
      "| - code2text_java      |      1|none  |     0|smoothed_bleu_4| 4.9707|±  |4.9707|\n",
      "| - code2text_javascript|      1|none  |     0|smoothed_bleu_4| 3.3021|±  |3.3021|\n",
      "| - code2text_php       |      1|none  |     0|smoothed_bleu_4| 0.0000|±  |0.0000|\n",
      "| - code2text_python    |      1|none  |     0|smoothed_bleu_4| 9.9119|±  |1.7294|\n",
      "| - code2text_ruby      |      3|none  |     0|smoothed_bleu_4| 0.0000|±  |0.0000|\n",
      "\n",
      "|      Groups       |Version|Filter|n-shot|    Metric     |Value|   |Stderr|\n",
      "|-------------------|-------|------|-----:|---------------|----:|---|-----:|\n",
      "|codexglue_code2text|N/A    |none  |     0|smoothed_bleu_4|4.927|±  |1.1091|\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                code2text_go/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         code2text_go/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              code2text_java/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       code2text_java/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        code2text_javascript/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: code2text_javascript/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               code2text_php/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        code2text_php/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            code2text_python/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     code2text_python/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              code2text_ruby/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       code2text_ruby/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         codexglue_code2text/smoothed_bleu_4 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  codexglue_code2text/smoothed_bleu_4_stderr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          code2text_go/alias  - code2text_go\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                code2text_go/smoothed_bleu_4 11.3772\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         code2text_go/smoothed_bleu_4_stderr 2.38404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        code2text_java/alias  - code2text_java\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              code2text_java/smoothed_bleu_4 4.97075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       code2text_java/smoothed_bleu_4_stderr 4.97075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  code2text_javascript/alias  - code2text_javascr...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        code2text_javascript/smoothed_bleu_4 3.30211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: code2text_javascript/smoothed_bleu_4_stderr 3.30211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                         code2text_php/alias  - code2text_php\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               code2text_php/smoothed_bleu_4 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        code2text_php/smoothed_bleu_4_stderr 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      code2text_python/alias  - code2text_python\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            code2text_python/smoothed_bleu_4 9.91188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     code2text_python/smoothed_bleu_4_stderr 1.7294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                        code2text_ruby/alias  - code2text_ruby\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              code2text_ruby/smoothed_bleu_4 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       code2text_ruby/smoothed_bleu_4_stderr 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   codexglue_code2text/alias codexglue_code2text\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         codexglue_code2text/smoothed_bleu_4 4.92699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  codexglue_code2text/smoothed_bleu_4_stderr 1.10914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mearnest-armadillo-20\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/cosmo3769/llm_eval_benchmark_lightning_ai/runs/8b8ucxhd/workspace\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 2 media file(s), 3 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240328_170043-8b8ucxhd/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!lm_eval \\\n",
    "    --model gguf \\\n",
    "    --model_args base_url=http://localhost:8000 \\\n",
    "    --tasks codexglue_code2text \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size auto \\\n",
    "    --output_path output/starcoderbase-3b-GGUF \\\n",
    "    --limit 2 \\\n",
    "    --wandb_args project=llm_eval_benchmark_lightning_ai \\\n",
    "    --log_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
