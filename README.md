# Quantized-LLMs

Visit the docs link for [Literature Review](https://docs.google.com/document/d/13AKlV_DhqfleW82-5kgPufhFQnpCeg1DgRHWcGOVBuI/edit?usp=sharing).

Check all the colab notebooks [here](https://github.com/cosmo3769/Quantized-LLMs/tree/main/notebooks).

Check the document on LLM Quantization and Benchmarking [here](https://github.com/cosmo3769/Quantized-LLMs/blob/main/QUANTIZE_and_BENCHMARK.md). It includes all my implementation details, challenges and adaptations.

Check the document on Deploying LLM to Mobile [here](https://github.com/cosmo3769/Quantized-LLMs/blob/main/DEPLOY_MOBILE_GUIDE.md). It includes all my implementation details, challenges and adaptations.

## Published studio at [Lightning AI](https://lightning.ai/cosmo3769)

* [Post-Training Quantization to GGUF format and Evaluation](https://lightning.ai/cosmo3769/studios/post-training-quantization-to-gguf-format-and-evaluation)
* [Post-Training Quantization to GPTQ format and Evaluation](https://lightning.ai/cosmo3769/studios/post-training-quantization-to-gptq-format-and-evaluation)

## To-Dos

- [x] Benchmark GGUF format quantized model using lm-evaluation-harness and llama-cpp-python
- [ ] HumanEval benchmark (non-quantized, quantized (GPTQ, GGUF))
- [ ] Research SmoothQuant
- [ ] Pruning
- [ ] Distillation
